{
    "collab_server" : "",
    "contents" : "---\ntitle: 'Real Time Location Systems: Indoor Positioning Sytems Using K-Nearest Neighbors'\nauthor: \"Dennis Murray, Jared Law, Julien Battaillard, Cory Nichols\"\ndate: \"February 20th, 2018\"\noutput:\n  html_notebook: default\n  word_document: default\n---\n\n## Abstract\nThe majority of people utilizing real time location systems  (RTLS) take them for granted. For example, GPS navigation on a cellular phone or tracking an Amazon package online utilize RTLS to communicate critical location information to consumers via a button click. RTLS is also a component in inventory management and logistics for many different industries. Companies such as Dell pioneered inventory management systems utilizing RTLS [1]. While applications are vast, RTLS is commonly used at room level and at entry ways of a building for security and tracking purposes. In this paper, we extend analysis from Nolan and Temple Lang [2] using location data from a handheld device and six access points inside of a building. We investigate the impact of leaving out a single access point on the statistical RTLS developed in Nolan and Temple Lang's research. We also extend the statistical RTLS developed in [2] by using a weighted K-nearest neighbors method. Results show that (results for MAC analysis here). We also find greater success using a weighted K-nearest neighbors approach in determining location given the data and infrastructure layout.\n\n## Introduction\n\nReal time location systems (RTLS) automatically track and identify the location of people or objects wirelessly. A classic RTLS example is location tracking of objects in a room, warehouse or other enclosed space. Hardware such as bluetooth tags or cell phones are used as mobile beacons to communicate with strategically placed readers or access points around the room. These beacons can be attached to humans, other devices, products or even robots [1]. Each beacon produces a signal that is read by access points or other tags around the room. Each signal provides data used to determine the location of the mobile device. Software applications utilizing triangulation, trilateration or a combination of location determination algorithms actively translate this location data and produce usable interfaces for humans to identify the location of a target.\n\nApplications for RTLS are vast and extend beyond a simple enclosed space. Advances in wireless technologies and proliferation of tracking tags have made real time location systems ubiquitous in manufacturing, inventory management and navigation [3]. Current location identification of a package is a popular use of RTLS technology. However, tracking previous location history and tracing locations to predict future locations are also common tasks, especially in inventory management and logistics.\n\nIn this paper, we extend previous analysis by Nolan and Temple Lang [2] using indoor wireless signal strength data from Mannheim University. These data are generated from a single mobile device at 166 locations on a single floor of a building. Eight orientation angles are considered for each position and 110 readings are taken for each (x,y) location, angle combination. Seven access points (readers) provide signal strength data to the mobile device. In their analysis, Nolan and Temple Lang implement an indoor positioning system using an average-based K-nearest neighbors model. The model is used to predict the location of a mobile device on the same floor using previously unseen signal strength data. The authors drop an access point from their data set and use six of seven access points to build their K-nearest neighbors model. We investigate the accuracy of the authors' K-nearest neighbors model utilizing the access point previously not considered. We also extend the average-based K-nearest neighbors approach by considering a weighted K-nearest neighbors model for predicting the location of the mobile device.\n\n## Literature Review\nJared and Cory (Jared)\n\n## Methods\n\n*Analysis of Extraneous MAC Address*\n\nDennis and Julien (Dennis)\n\n\n*Weighted K-Nearest Neighbors Implementation*\n\nNolan and Temple Lang [2] implement a k nearest neighbors model utilizing the mean of known neighbors (x,y) location to predict the position of new records containing signal strengths from six access points on the building floor. Given data exploration by the authors, it is determined that orientation is a significant factor affecting signal strength. In establishing a training data set, the authors take \n\n\n```{r out.width='100%'}\nknitr::include_graphics('Geo_BoxplotSignalByMacAngle.pdf')\n```\n\n\n## Results\nCory and Dennis for each methods section above since they kind of go hand in hand\n\n## Conclusion and Future Work\nDennis and Julien (Julien)\n\n## References\nhttp://www.academia.edu/23256794/Dells_Just_In_Time_Inventory_Management_system\n\nNolan Temple Lang book\n\nhttps://www.technologyreview.com/the-download/609672/amazons-investment-in-robots-is-eliminating-human-jobs/\n\nhttp://searchmobilecomputing.techtarget.com/definition/real-time-location-system-RTLS\n\nReferences\n\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC3408320/ - RTLS in healthcare\n\nhttp://ieeexplore.ieee.org/abstract/document/4679157/ - RTLS in warehouse management using WiFi and RFID\n\nhttps://patents.google.com/patent/US20120065483A1/en - RTLS for LIVESTOCK management and health analysis\n\n\n\n\n```{r import, echo=FALSE}\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(fields)\nlibrary(lattice)\n\n```\n\n```{r data_cleanup, echo=FALSE}\n#This is the code from Nolan and Lang Chapter 1\noptions(digits = 2)\n\n# Read in the text file to a matrix called txt\ntxt = readLines(\"Data/offline.final.trace.txt\")\n\n# get a count of lines that have a # in the first character location \nsum(substr(txt, 1, 1) == \"#\")\n\n# total lines in the txt matrix\nlength(txt)\n\n# as a test, strsplit the 4th line on semicolons, print to screen\nstrsplit(txt[4], \";\")[[1]]\n\n# store results of string of the 4th line to a vector\ntokens = strsplit(txt[4], \"[;=,]\")[[1]]\n\n# print tokens 1:10 to screen\ntokens[1:10]\n\n# extract the 2nd, 4th, 6:8 and 10th elements to the screen\n# these tokens make up the handheld device\ntokens[c(2, 4, 6:8, 10)]\n\n# get features for readings (all else not == handheld device)\ntokens[ - ( 1:10 ) ]\n\n# assign a matrix of everything except elements 1:10 to a 4 coloumn matrix called tmp\n# build a matrix for each section of the data and bind them together using cbind\ntmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE) # get all signals\nmat = cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp), # repeat handheld device data\n                   ncol = 6, byrow = TRUE), \n            tmp)\n#print shape of mat to screen\ndim(mat)\n\n# make this extendable, create function to repeat process for each line in dataset\n# this will create individual matrices for each line in the data (not efficient)\nprocessLine =\nfunction(x)\n{\n  tokens = strsplit(x, \"[;=,]\")[[1]]\n  tmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE)\n  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp),\n               ncol = 6, byrow = TRUE), tmp)\n}\n\n# apply to 17 lines of first file at x,y = 0,0 and pos = 0.0\n# creates 17 matrices, returns them in a list\ntmp = lapply(txt[4:20], processLine)\n\n# count the number of records in each matrix created\n# use sapply (preserves dimensions tmp) to show the number of rows in each row in tmp\nsapply(tmp, nrow)\n\n# stack the matrices using rbind and do.call\noffline = as.data.frame(do.call(\"rbind\", tmp))\ndim(offline)\n\n# now do this for the entire dataset\n# create a list called lines that contains the lines that don't start with a # \nlines = txt[ substr(txt, 1, 1) != \"#\" ]\ntmp = lapply(lines, processLine)\n\n\n# adjust induction function for issue where no readings for a position x,y and orientation\n# discard if we only find tokens for handheld device\nprocessLine = function(x)\n{\n  tokens = strsplit(x, \"[;=,]\")[[1]]\n  \n  if (length(tokens) == 10)  # this is the adjustment, checks to see if we have signal responses, if not, returns null\n    return(NULL)\n \n  tmp = matrix(tokens[ - (1:10) ], ncol= 4, byrow = TRUE)\n  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6, \n               byrow = TRUE), tmp)\n}\n\noptions(error = recover, warn = 1)\ntmp = lapply(lines, processLine)\noffline = as.data.frame(do.call(\"rbind\", tmp), \n                        stringsAsFactors = FALSE)\n\n# offline dataframe in tidy format with readings down instead of across\ndim(offline)\n\n# clean data and build represenation for analysis\n\n# rename the columns, transform numeric values\nnames(offline) = c(\"time\", \"scanMac\", \"posX\", \"posY\", \"posZ\", \n                   \"orientation\", \"mac\", \"signal\", \n                   \"channel\", \"type\")\n\nnumVars = c(\"time\", \"posX\", \"posY\", \"posZ\", \n            \"orientation\", \"signal\")\noffline[ numVars ] =  lapply(offline[ numVars ], as.numeric)\n\n# drop all vars with 1 as mode and remove type variable\n# only want to keep access point (type 3)\noffline = offline[ offline$type == \"3\", ]\noffline = offline[ , \"type\" != names(offline) ] # this filters out type from columns\ndim(offline)\n\n# transform time from ms to s in order to get POSIXt format\noffline$rawTime = offline$time\noffline$time = offline$time/1000 # convert from ms to s\nclass(offline$time) = c(\"POSIXt\", \"POSIXct\")\n\n# check the class of each variable in our dataset\nunlist(lapply(offline, class))\n\n# summary stats on our numeric vars\nsummary(offline[, numVars])\n\n# only one MAC for our scanning device: 00:02:2D:21:0F:33\nsummary(sapply(offline[ , c(\"mac\", \"channel\", \"scanMac\")],\n                as.factor))\n\n# remove scanMac and posZ from offline df: no posZ in data and only one scanMac\noffline = offline[ , !(names(offline) %in% c(\"scanMac\", \"posZ\"))]\n\n# exploring orientation, far more than 8 values for orientation\nlength(unique(offline$orientation))\n\n# values distributed in clusters around what we'd expect\nplot(ecdf(offline$orientation))\n\n# build pdf export\npdf(file = \"Images/Geo_ECDFOrientation.pdf\", width = 10, height = 7)\noldPar = par(mar = c(4, 4, 1, 1))\nplot(ecdf(offline$orientation), pch = 19, cex = 0.3,\n     xlim = c(-5, 365), axes = FALSE,\n     xlab = \"orientation\", ylab = \"Empirical CDF\", main = \"\")\nbox()\naxis(2)\naxis(side = 1, at = seq(0, 360, by = 45))\npar(oldPar)\ndev.off()\n\n\npdf(file = \"Images/Geo_DensityOrientation.pdf\", width = 10, height = 5)\noldPar = par(mar = c(4, 4, 1, 1))\nplot(density(offline$orientation, bw = 2), \n xlab = \"orientation\", main = \"\")\npar(oldPar)\ndev.off()\n\n# to normalize, build function to round off orientation\nroundOrientation = function(angles) {\n  refs = seq(0, by = 45, length  = 9)\n  q = sapply(angles, function(o) which.min(abs(o - refs))) # which angle is orientation value closest to? get index\n  c(refs[1:8], 0)[q] # map index to reference positions, taking care to make sure 360 == 0\n}\n\noffline$angle = roundOrientation(offline$orientation)\n\n# boxplot showing transforms of orientation to nearest 45 deg angle\nwith(offline, boxplot(orientation ~ angle,\n                      xlab=\"nearest 45 degree angle\",\n                      ylab=\"orientation\"))\n\npdf(file = \"Images/Geo_BoxplotAngle.pdf\", width = 10)\nwith(offline, boxplot(orientation ~ angle,\n                      xlab=\"nearest 45 degree angle\",\n                      ylab=\"orientation\"))\noldPar = par(mar = c(4, 4, 1, 1))\npar(oldPar)\ndev.off()\n\n\n# Exploring MAC Addresses\nc(length(unique(offline$mac)), length(unique(offline$channel)))\n\n# check counts of observationsf or MAC addresses\ntable(offline$mac)\n\n# obviously extra MAC addresses, some with not many readings, get rid of those\n# keep records from 7 top read devices (one more than we need)\nsubMacs = names(sort(table(offline$mac), decreasing = TRUE))[1:7]\n\n# keep rows with subMacs identified only, discarding others in training set\noffline = offline[ offline$mac %in% subMacs, ]\n\n# create a table of counts for mac and channel and filter it\nmacChannel = with(offline, table(mac, channel))\napply(macChannel, 1, function(x) sum(x > 0))\n# one unique channel per MAC\n\n# eliminate channel from offline dataset, not necessary for analysis\noffline = offline[ , \"channel\" != names(offline)]\n```\n\n``` {r eda, echo=FALSE}\n# EXPLORING POSITION OF HANDHELD DEVICE\n\n# how many unique x,y positions?\nlocDF = with(offline, \n             by(offline, list(posX, posY), function(x) x))\nlength(locDF)\n# way too many, > 166 quoted\n\n# which locations are empty: 310\nsum(sapply(locDF, is.null))\n\n# remove nulls and we get 166 unique x,y locs, good to go\nlocDF = locDF[ !sapply(locDF, is.null) ]\nlength(locDF)\n\n# get counts by x,y position, should be ~5300 110 readings * 8 angles * 6 positions \nlocCounts = sapply(locDF, nrow)\n\nlocCounts = sapply(locDF, \n                   function(df) \n                     c(df[1, c(\"posX\", \"posY\")], count = nrow(df)))\n\nclass(locCounts)\n\ndim(locCounts)\n\nlocCounts[ , 1:8]\n\nlocCounts = t(locCounts)\nplot(locCounts, type = \"n\", xlab = \"\", ylab = \"\")\ntext(locCounts, labels = locCounts[,3], cex = 0.8, srt = 45)\n\npdf(file = \"Images/Geo_XYByCount.pdf\", width = 10)\noldPar = par(mar = c(3.1, 3.1, 1, 1))\n\nlocCounts = t(locCounts)\nplot(locCounts, type = \"n\", xlab = \"\", ylab = \"\")\ntext(locCounts, labels = locCounts[,3], cex = .8, srt = 45)\n\npar(oldPar)\ndev.off()\n\n\n# CREATING A FUNCTION TO PREPARE THE DATA\nreadData = \n  function(filename = 'Data/offline.final.trace.txt', \n           subMacs = c(\"00:0f:a3:39:e1:c0\", \"00:0f:a3:39:dd:cd\", \"00:14:bf:b1:97:8a\",\n                       \"00:14:bf:3b:c7:c6\", \"00:14:bf:b1:97:90\", \"00:14:bf:b1:97:8d\",\n                       \"00:14:bf:b1:97:81\"))\n  {\n    txt = readLines(filename)\n    lines = txt[ substr(txt, 1, 1) != \"#\" ]\n    tmp = lapply(lines, processLine)\n    offline = as.data.frame(do.call(\"rbind\", tmp), \n                            stringsAsFactors= FALSE) \n    \n    names(offline) = c(\"time\", \"scanMac\", \n                       \"posX\", \"posY\", \"posZ\", \"orientation\", \n                       \"mac\", \"signal\", \"channel\", \"type\")\n    \n     # keep only signals from access points\n    offline = offline[ offline$type == \"3\", ]\n    \n    # drop scanMac, posZ, channel, and type - no info in them\n    dropVars = c(\"scanMac\", \"posZ\", \"channel\", \"type\")\n    offline = offline[ , !( names(offline) %in% dropVars ) ]\n    \n    # drop more unwanted access points\n    offline = offline[ offline$mac %in% subMacs, ]\n    \n    # convert numeric values\n    numVars = c(\"time\", \"posX\", \"posY\", \"orientation\", \"signal\")\n    offline[ numVars ] = lapply(offline[ numVars ], as.numeric)\n\n    # convert time to POSIX\n    offline$rawTime = offline$time\n    offline$time = offline$time/1000\n    class(offline$time) = c(\"POSIXt\", \"POSIXct\")\n    \n    # round orientations to nearest 45\n    offline$angle = roundOrientation(offline$orientation)\n      \n    return(offline)\n  }\n\nofflineRedo = readData()\n\n# check for equality\nidentical(offline, offlineRedo)\n\n# what variables did we use as global? these our are dependencies\nlibrary(codetools)\nfindGlobals(readData, merge =FALSE)$variables\n```\n\n```{r eda_signalstr, echo=FALSE}\n# INVESTIGATING SIGNAL STRENGTH\n\npdf(file = \"Images/Geo_BoxplotSignalByMacAngle.pdf\", width = 7)\noldPar = par(mar = c(3.1, 3, 1, 1))\n\nlibrary(lattice)\n# investigate variability of angle for each MAC given one x,y position\n# we exclude MAC 00:0f:a3:39:dd:cd here, can see that angle affects\n# the signal fr some mac addresses, especially those with stronger signals\nbwplot(signal ~ factor(angle) | mac, \n       data = offline, \n       subset = posX == 2 & posY == 12 \n                & mac != \"00:0f:a3:39:dd:cd\", \n       layout = c(2,3))\n\npar(oldPar)\ndev.off()\n\n# overall statistics for signal, range of -98 to -25 (lower is stronger)\nsummary(offline$signal)\n\npdf(file = \"Images/Geo_DensitySignalByMacAngle.pdf\", width = 8, height = 12)\noldPar = par(mar = c(3.1, 3, 1, 1))\n\n# investigate distribution of signals for one x,y & each angle\n# non-normality and dual-modal apparent, e.g. 00:14:bf:b1:97:8a, at 270 deg orientation\ndensityplot( ~ signal | mac + factor(angle), \n             data = offline,\n             subset = posX == 24 & posY == 4 & \n                         mac != \"00:0f:a3:39:dd:cd\",\n             bw = 0.5, plot.points = FALSE)\n\npar(oldPar)\ndev.off()\n\n#offline = offline[ offline$mac != \"00:0f:a3:39:dd:cd\", ]\n\n# create table of summary stats by Location, Angle and AP\noffline$posXY = paste(offline$posX, offline$posY, sep = \"-\") # concat x,y\n\nbyLocAngleAP = with(offline, \n                    by(offline, list(posXY, angle, mac), \n                       function(x) x))\n\n# calculate summary statistics, reduce down to single summary line\nsignalSummary = \n  lapply(byLocAngleAP,            \n         function(oneLoc) {\n           ans = oneLoc[1, ]\n           ans$medSignal = median(oneLoc$signal)\n           ans$avgSignal = mean(oneLoc$signal)\n           ans$num = length(oneLoc$signal)\n           ans$sdSignal = sd(oneLoc$signal)\n           ans$iqrSignal = IQR(oneLoc$signal)\n           ans\n           })\n\n# bind all the summary lines together\nofflineSummary = do.call(\"rbind\", signalSummary)     \n\npdf(file = \"Images/Geo_BoxplotSignalSDByAvg.pdf\", width = 10)\noldPar = par(mar = c(3.1, 3, 1, 1))\n\n# create box and whisker for standard deviation for each avg Signal calculated in summary\n# shows us how variable signal ranges can be\n# more variable the stronger the signal is\nbreaks = seq(-90, -30, by = 5)\nbwplot(sdSignal ~ cut(avgSignal, breaks = breaks),\n       data = offlineSummary, \n       subset = mac != \"00:0f:a3:39:dd:cd\",\n       xlab = \"Mean Signal\", ylab = \"SD Signal\")\n\npar(oldPar)\ndev.off()\n\n\npdf(file = \"Images/Geo_ScatterMean-Median.pdf\", width = 10)\noldPar = par(mar = c(4.1, 4.1, 1, 1))\n\n# examine skewness of signal strength (avg - med signal) vs num observations\n# if normal should be higher densities in center\nwith(offlineSummary,\n     smoothScatter((avgSignal - medSignal) ~ num,\n                   xlab = \"Number of Observations\", \n                   ylab = \"mean - median\"))\nabline(h = 0, col = \"#984ea3\", lwd = 2)\n\n# fit LOESS line, shows that there is not a lot of difference or trend\n# skewness is minimal\nlo.obj = \n  with(offlineSummary,\n       loess(diff ~ num, \n             data = data.frame(diff = (avgSignal - medSignal),\n                               num = num)))\n\nlo.obj.pr = predict(lo.obj, newdata = data.frame(num = (70:120)))\nlines(x = 70:120, y = lo.obj.pr, col = \"#4daf4a\", lwd = 2)\n\npar(oldPar)\ndev.off()\n \n\n# THE RELATIONSHIP BETWEEN SIGNAL AND DISTANCE\n\n# contour plot investigation\n# one MAC and one orientaiton\noneAPAngle = subset(offlineSummary, \n                    mac == subMacs[5] & angle == 0)\n\n\nlibrary(fields)\n# tps = thin plate splines, fit surface to signal strength values at observed locations\n# must pass a Z here, which is our avg signal, this will reflect our color\nsmoothSS = Tps(oneAPAngle[, c(\"posX\",\"posY\")], \n               oneAPAngle$avgSignal)\n\nvizSmooth = predictSurface(smoothSS)\n\nplot.surface(vizSmooth, type = \"C\")\n\n# add locations where measurements were taken\npoints(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5)\n\n# create a function for charting purposes, to include multiple contour plots\nsurfaceSS = function(data, mac, angle = 45) {\n  require(fields)\n  oneAPAngle = data[ data$mac == mac & data$angle == angle, ]\n  smoothSS = Tps(oneAPAngle[, c(\"posX\",\"posY\")], \n                 oneAPAngle$avgSignal)\n  vizSmooth = predictSurface(smoothSS)\n  plot.surface(vizSmooth, type = \"C\", \n               xlab = mac, ylab = \"\", xaxt = \"n\", yaxt = \"n\")\n  points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5) \n}\n\nparCur = par(mfrow = c(2,2), mar = rep(1, 4))\n\n# make 4 calls, shows corridor effect, signal strength of course strongest closest to AP\nmapply(surfaceSS, mac = subMacs[ rep(c(5, 1,2), each = 2) ], \n       angle = rep(c(0, 135, 180), 2),\n       data = list(data = offlineSummary))\n \npar(parCur)\n\n# the two similar macs are subMacs[1,2]\n# remove similar MAC\nofflineSummary = subset(offlineSummary, mac != subMacs[2])\n\n# create a mtrix with relevant positions for six access points on floor plan\nAP = matrix( c( 7.5, 6.3, 2.5, -.8, 12.8, -2.8,  \n                1, 14, 33.5, 9.3,  33.5, 2.8),\n            ncol = 2, byrow = TRUE,\n            dimnames = list(subMacs[ -2 ], c(\"x\", \"y\") ))\n\nAP\n\n# relationship between signal stregnth and distance from AP\n# distances from locations of the device emitting vs access point receiving\ndiffs = offlineSummary[ , c(\"posX\", \"posY\")] - \n          AP[ offlineSummary$mac, ] # ordered and indexed by offlineSummary\n\nofflineSummary$dist = sqrt(diffs[ , 1]^2 + diffs[ , 2]^2)\n\nxyplot(signal ~ dist | factor(mac) + factor(angle), \n       data = offlineSummary, pch = 19, cex = 0.3,\n       xlab =\"distance\")\n\npdf(file=\"Images/Geo_ScatterSignalDist.pdf\", width = 7, height = 10)\noldPar = par(mar = c(3.1, 3.1, 1, 1))\nlibrary(lattice)\nxyplot(signal ~ dist | factor(mac) + factor(angle), \n       data = offlineSummary, pch = 19, cex = 0.3,\n       xlab =\"distance\")\npar(oldPar)\ndev.off()\n\n```\n\n```{r knn_work, echo=FALSE}\n\n# using only signals to APs from previously trained locations\n# need to reformat data so signal strength is across columns\n\nmacs = unique(offlineSummary$mac)\n# read test data\nonline = readData(\"Data/online.final.trace.txt\", subMacs = macs)\n\n# set up unique XY\nonline$posXY = paste(online$posX, online$posY, sep = \"-\")\n\n# 60 unique positions\nlength(unique(online$posXY))\n\n# using only one orientation for each location\ntabonlineXYA = table(online$posXY, online$angle)\ntabonlineXYA[1:10, ]\n\n# pivot data to include signals across columns\n# take the mean of signal for each mac position along columns\nkeepVars = c(\"posXY\", \"posX\", \"posY\", \"orientation\", \"angle\")\nbyLoc = with(online, \n             by(online, list(posXY), \n                function(x) {\n                  ans = x[1, keepVars]\n                  avgSS = tapply(x$signal, x$mac, mean)\n                  y = matrix(avgSS, nrow = 1, ncol = 6,\n                        dimnames = list(ans$posXY, names(avgSS)))\n                  cbind(ans, y)\n                }))\n\nonlineSummary = do.call(\"rbind\", byLoc)  \n\ndim(onlineSummary)\n\n# rename\nnames(onlineSummary)\n\n# ANGLE ALIGNMENT\n# want to find records in offline data (training) that have similar orientations to our new observations\n# orientation CAN impact signal strength as already evidenced visually in boxplots\n\n# finding nearest angles to help filter training data before aggregation:\nm = 3; angleNewObs = 230\nrefs = seq(0, by = 45, length  = 8)\nnearestAngle = roundOrientation(angleNewObs)\n  \nif (m %% 2 == 1) {\n  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)\n} else {\n  m = m + 1\n  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)\n  if (sign(angleNewObs - nearestAngle) > -1) \n    angles = angles[ -1 ]\n  else \n    angles = angles[ -m ]\n}\nangles = angles + nearestAngle\nangles[angles < 0] = angles[ angles < 0 ] + 360\nangles[angles > 360] = angles[ angles > 360 ] - 360\n\n# with desired angles, select observations from offlineSummary for training\nofflineSubset = \n  offlineSummary[ offlineSummary$angle %in% angles, ]\n\n# then reshape training set to match test set, with signals across columns\nreshapeSS = function(data, varSignal = \"signal\", \n                     keepVars = c(\"posXY\", \"posX\",\"posY\")) {\n  byLocation =\n    with(data, by(data, list(posXY), \n                  function(x) {\n                    ans = x[1, keepVars]\n                    avgSS = tapply(x[ , varSignal ], x$mac, mean)\n                    y = matrix(avgSS, nrow = 1, ncol = 6,\n                               dimnames = list(ans$posXY,\n                                               names(avgSS)))\n                    cbind(ans, y)\n                  }))\n\n  newDataSS = do.call(\"rbind\", byLocation)\n  return(newDataSS)\n}\n\n# build all of this into a funciton\ntrainSS = reshapeSS(offlineSubset, varSignal = \"avgSignal\")\n\n# wrap code to select angles and reshape the training set\n# takes angle of new observation and associated angles from dataset using m\n# angleNewObs sets reference point\n# m is the number of angles to keep between 1 and 5 around reference point\n# signals is the training dataset to filter and reshape\nselectTrain = function(angleNewObs, signals = NULL, m = 1){\n  refs = seq(0, by = 45, length  = 8)\n  nearestAngle = roundOrientation(angleNewObs)\n  \n  if (m %% 2 == 1) \n    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)\n  else {\n    m = m + 1\n    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)\n    if (sign(angleNewObs - nearestAngle) > -1) \n      angles = angles[ -1 ]\n    else \n      angles = angles[ -m ]\n  }\n  angles = angles + nearestAngle\n  angles[angles < 0] = angles[ angles < 0 ] + 360\n  angles[angles > 360] = angles[ angles > 360 ] - 360\n  angles = sort(angles) \n  \n  offlineSubset = signals[ signals$angle %in% angles, ]\n  reshapeSS(offlineSubset, varSignal = \"avgSignal\")\n}\n\n# example\n# use angle of 130 for offline summary taking 135 and two closest angles for training set\n# reshape by aggregating, taking average of signals for each mac, angles considered\ntrain130 = selectTrain(130, offlineSummary, m = 3)\n\nhead(train130)\n\nlength(train130[[1]])\n\n\n\n\n# FINDING NEAREST NEIGHBORS\n# takes numeric vector of 6 new signal strengths and result of selectTrain() training set\nfindNN = function(newSignal, trainSubset) {\n  diffs = apply(trainSubset[ , 4:9], 1, \n                function(x) x - newSignal) # this inverts, places x,y on cols when called as.numeric\n  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) ) # this gets our distance (euclidean)\n  closest = order(dists) # orders our distances in ascending\n  return(trainSubset[closest, 1:3 ]) # returns the subset from training with closest distances, gives xy ID, x, y\n}\n\n\n# weighted nearest neighbors, returns numerator of weight 1/distance\nfindWtdNN = function(newSignal, trainSubset) {\n  diffs = apply(trainSubset[ , 4:9], 1, \n                function(x) x - newSignal) \n  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) ) \n  closest = order(dists) # orders distances ascending\n  closeXY = trainSubset[closest, 1:3 ]\n  weight = as.numeric(1/dists[closest]) # calculate numerator for weights, we'll filter these based on K in predXY\n  return(cbind(closeXY, weight)) # add in numerator for our weights\n}\n\n# prediction using nearest neighbors from training set\npredXY = function(newSignals, newAngles, trainData, \n                  numAngles = 1, k = 3){\n  \n  closeXY = list(length = nrow(newSignals))\n  \n  for (i in 1:nrow(newSignals)) {\n    trainSS = selectTrain(newAngles[i], trainData, m = numAngles) # select training set based on angle of test obs, num of angles in proximity\n    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]), trainSS) # find nearest neighbors, return closest in training set\n  }\n  estXY = lapply(closeXY, # loop over each xy position-based dataframe\n                 function(x) sapply(x[ , 2:3], \n                                    function(x) mean(x[1:k]))) # take a simple average of x,y positions\n  estXY = do.call(\"rbind\", estXY) # pull predictions together for each observation xy in test set\n  return(estXY)\n}\n\n# weighted prediction\npredXYwtd = function(newSignals, newAngles, trainData, \n                     numAngles = 1, k = 3){\n  \n  closeXY = list(length = nrow(newSignals))\n  \n  for (i in 1:nrow(newSignals)) {\n    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)\n    base = findWtdNN(newSignal = as.numeric(newSignals[i, ]), trainSS) # get matrix of x,y, numerator for weights\n    wts = append(base[1:k, 4]/sum(base[1:k, 4]), rep(0, nrow(base)-k))  # calculate weights based on K, append zero array for delta of len-k\n    base[, 2:3] = base[, 2:3]*wts # multiply weights array * matrix of x,y to get weighted vals\n    closeXY[[i]] = base[,1:3] # append weighted xy, x, y values to list\n  }\n  estXY = lapply(closeXY, # loop over each xy position-based dataframe\n                 function(x) sapply(x[ , 2:3], function(x) sum(x))) # sum all as neighbors > k == 0 now, and x,y is already weighted!\n  estXY = do.call(\"rbind\", estXY) # pull predictions together for each observation xy in test set\n  return(estXY)\n}\n```\n\n```{r knnsummary, echo=FALSE}\n\n# this is testing on the test set... not optimal, validation is in the next section\n# we are also using 3 angles to aggregate and average for our training set to compare to\nestXYk1 = predXY(newSignals = onlineSummary[ , 6:11], \n                 newAngles = onlineSummary[ , 4], \n                 offlineSummary, numAngles = 3, k = 1)\n\nestXYk3 = predXY(newSignals = onlineSummary[ , 6:11], \n                 newAngles = onlineSummary[ , 4], \n                 offlineSummary, numAngles = 3, k = 3)\n\nestXYk3wtd = predXYwtd(newSignals = onlineSummary[ , 6:11], \n                 newAngles = onlineSummary[ , 4], \n                 offlineSummary, numAngles = 3, k = 3)\n\n# with 7 neighbors\nestXYk7 = predXY(newSignals = onlineSummary[ , 6:11], \n                 newAngles = onlineSummary[ , 4], \n                 offlineSummary, numAngles = 3, k = 7)\n\nestXYk7wtd = predXYwtd(newSignals = onlineSummary[ , 6:11], \n                 newAngles = onlineSummary[ , 4], \n                 offlineSummary, numAngles = 3, k = 7)\n\n\nactualXY = onlineSummary[ , c(\"posX\", \"posY\")]\n\ncalcError = \nfunction(estXY, actualXY) \n   sum( rowSums( (estXY - actualXY)^2) )\n\nsapply(list(estXYk1, estXYk3, estXYk3wtd), calcError, actualXY)\n\n# testing without CV folds, full test set, takes about 2 minutes\n# this is not proper error testing! \n\nerror_mean_vec = c()\nerror_wtd_vec = c()\n\nfor (i in seq(1,20,2)){\n  \n       mean = predXY(newSignals = onlineSummary[ , 6:11], \n             newAngles = onlineSummary[ , 4], \n             offlineSummary, numAngles = 3, k = i)\n       error_mean = calcError(mean, actualXY)\n       cat(\"With\",i,\"Neighbors Summary:\\n\\nMean KNN Error\", error_mean)\n       error_mean_vec = append(error_mean_vec, error_mean)\n       \n       wtd = predXYwtd(newSignals = onlineSummary[ , 6:11], \n             newAngles = onlineSummary[ , 4], \n             offlineSummary, numAngles = 3, k = i)\n       error_wtd = calcError(wtd, actualXY)\n       cat(\"\\nWeighted KNN Error\", error_wtd)\n       error_wtd_vec = append(error_wtd_vec, error_wtd)\n       cat(\"\\nWeighted KNN minus Mean KNN Error:\", error_wtd - error_mean,\"\\n\\n\")\n} \n\n\n# visualize learning curve based on squared error, iterating over K\ndf = as_data_frame(cbind(error_mean_vec, error_wtd_vec, k=seq(1,20,2)))\n\npdf(file = \"Images/KNNvWTDKNNfull.pdf\", width = 10)\noldPar = par(mar = c(4.1, 4.1, 1, 1))\n\n# plot learning curve\nlibrary(ggplot2)\ndf %>%\nggplot()+\n  geom_line(mapping=aes(x=k, y=error_mean_vec, color=\"mean KNN\"), show.legend = TRUE)+\n  geom_line(mapping=aes(x=k, y=error_wtd_vec, color=\"wtd KNN\"), linetype=\"dashed\", show.legend = TRUE)+\n  ggtitle('Learning Curve given K')+\n  labs(y=\"error\")\n\npar(oldPar)\ndev.off()\n\n\n# show errors on the floor\nfloorErrorMap = function(estXY, actualXY, trainPoints = NULL, AP = NULL){\n  \n    plot(0, 0, xlim = c(0, 35), ylim = c(-3, 15), type = \"n\",\n         xlab = \"\", ylab = \"\", axes = FALSE)\n    box()\n    if ( !is.null(AP) ) points(AP, pch = 15)\n    if ( !is.null(trainPoints) )\n      points(trainPoints, pch = 19, col=\"grey\", cex = 0.6)\n    \n    points(x = actualXY[, 1], y = actualXY[, 2], \n           pch = 19, cex = 0.8 )\n    points(x = estXY[, 1], y = estXY[, 2], \n           pch = 8, cex = 0.8 )\n    segments(x0 = estXY[, 1], y0 = estXY[, 2],\n             x1 = actualXY[, 1], y1 = actualXY[ , 2],\n             lwd = 2, col = \"red\")\n}\n\ntrainPoints = offlineSummary[ offlineSummary$angle == 0 & \n                              offlineSummary$mac == \"00:0f:a3:39:e1:c0\" ,\n                        c(\"posX\", \"posY\")]\n\npdf(file=\"Images/GEO_FloorPlanK3Errors.pdf\", width = 10, height = 7)\noldPar = par(mar = c(1, 1, 1, 1))\n\nfloorErrorMap(estXYk3, onlineSummary[ , c(\"posX\",\"posY\")], \n              trainPoints = trainPoints, AP = AP)\npar(oldPar)\ndev.off()\n\npdf(file=\"Images/GEO_FloorPlanK1Errors.pdf\", width = 10, height = 7)\noldPar = par(mar = c(1, 1, 1, 1))\nfloorErrorMap(estXYk1, onlineSummary[ , c(\"posX\",\"posY\")], \n              trainPoints = trainPoints, AP = AP)\npar(oldPar)\ndev.off()\n\npdf(file=\"Images/GEO_FloorPlanK7Errors.pdf\", width = 10, height = 7)\noldPar = par(mar = c(1, 1, 1, 1))\nfloorErrorMap(estXYk7, onlineSummary[ , c(\"posX\",\"posY\")], \n              trainPoints = trainPoints, AP = AP)\npar(oldPar)\ndev.off()\n\npdf(file=\"Images/GEO_FloorPlanK7WTDErrors.pdf\", width = 10, height = 7)\noldPar = par(mar = c(1, 1, 1, 1))\nfloorErrorMap(estXYk7wtd, onlineSummary[ , c(\"posX\",\"posY\")], \n              trainPoints = trainPoints, AP = AP)\npar(oldPar)\ndev.off()\n\n```\n\n\n```{r cross_validation, echo=FALSE}\n# cross validate over each location, using all 8 orientations and 6 MAC addresses\n# each fold has 166/11 = 15 locations\n# must randomly select\nv = 11\n# permute locations\npermuteLocs = sample(unique(offlineSummary$posXY))\n\n# to calculate folds, build a matrix with 11 columns and ~15 locations each\npermuteLocs = matrix(permuteLocs, ncol = v, \n                     nrow = floor(length(permuteLocs)/v))\n\n# get the first validation fold from our offline data\nonlineFold = subset(offlineSummary, posXY %in% permuteLocs[ , 1])\n\n# must re-summarize each fold to match onlineSummary format\n# selecting orientation at random to create our CV folds\nreshapeSS = function(data, varSignal = \"signal\", \n                     keepVars = c(\"posXY\", \"posX\",\"posY\"),\n                     sampleAngle = FALSE, \n                     refs = seq(0, 315, by = 45)) {\n  byLocation =\n    with(data, by(data, list(posXY), \n                  function(x) {\n                    if (sampleAngle) {\n                      x = x[x$angle == sample(refs, size = 1), ]}\n                    ans = x[1, keepVars]\n                    avgSS = tapply(x[ , varSignal ], x$mac, mean)\n                    y = matrix(avgSS, nrow = 1, ncol = 6,\n                               dimnames = list(ans$posXY,\n                                               names(avgSS)))\n                    cbind(ans, y)\n                  }))\n\n  newDataSS = do.call(\"rbind\", byLocation)\n  return(newDataSS)\n}\n\n# exclude MAC\noffline = offline[ offline$mac != \"00:0f:a3:39:dd:cd\", ]\n\nkeepVars = c(\"posXY\", \"posX\",\"posY\", \"orientation\", \"angle\")\n\n# build CV base from offline data in general\nonlineCVSummary = reshapeSS(offline, keepVars = keepVars, \n                            sampleAngle = TRUE)\n\n# an example of one fold\nonlineFold = subset(onlineCVSummary, \n                    posXY %in% permuteLocs[ , 1])\n\n# this is our training set\nofflineFold = subset(offlineSummary,\n                     posXY %in% permuteLocs[ , -1])\n\n# using both methods with k = 3\nestFold = predXY(newSignals = onlineFold[ , 6:11], \n                 newAngles = onlineFold[ , 4], \n                 offlineFold, numAngles = 3, k = 3)\n\nestFoldwtd = predXYwtd(newSignals = onlineFold[ , 6:11], \n                 newAngles = onlineFold[ , 4], \n                 offlineFold, numAngles = 3, k = 3)\n\nactualFold = onlineFold[ , c(\"posX\", \"posY\")]\ncalcError(estFoldwtd, actualFold)\n\n# formally test K out to 20 neighbors\nK = 20\nerr = rep(0, K)\nerr_wtd = rep(0,K) # weighted error\n\nfor (j in 1:v) {\n  onlineFold = subset(onlineCVSummary, \n                      posXY %in% permuteLocs[ , j])\n  offlineFold = subset(offlineSummary,\n                       posXY %in% permuteLocs[ , -j])\n  actualFold = onlineFold[ , c(\"posX\", \"posY\")]\n  \n  for (k in 1:K) {\n    estFold = predXY(newSignals = onlineFold[ , 6:11],\n                     newAngles = onlineFold[ , 4], \n                     offlineFold, numAngles = 3, k = k)\n    err[k] = err[k] + calcError(estFold, actualFold)\n    \n    estFold_wtd = predXYwtd(newSignals = onlineFold[ , 6:11], # add in weighted calculations\n                     newAngles = onlineFold[ , 4], \n                     offlineFold, numAngles = 3, k = k)\n    err_wtd[k] = err_wtd[k] + calcError(estFold_wtd, actualFold)\n  }\n}\n\npdf(file = \"Images/Geo_CVChoiceOfK.pdf\", width = 8, height = 6)\noldPar = par(mar = c(4, 3, 1, 1))\nplot(y = err, x = (1:K),  type = \"l\", lwd= 2,\n     ylim = c(0, 2100),\n     xlab = \"Number of Neighbors\",\n     ylab = \"Sum of Square Errors\")\nlines(y=err_wtd, x=1:K, lty = 2, lwd=2, col='red')\n\n\nrmseMin = min(err)\nkMin = which(err == rmseMin)[1]\n\nrmseMin_wtd = min(err_wtd)\nkMin_wtd = which(err_wtd == rmseMin_wtd)[1]\n\n```\n\n```{r addtl, echo=FALSE}\n# additional code not in book:\n\nsegments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4), \n         lty = 2, lwd = 2)\nsegments(x0 = kMin, x1 = kMin, y0 = 1100,  y1 = rmseMin, \n         col = grey(0.4), lty = 2, lwd = 2)\n\n#mtext(kMin, side = 1, line = 1, at = kMin, col = grey(0.4))\ntext(x = kMin - 2, y = rmseMin + 40, \n     label = as.character(round(rmseMin)), col = grey(0.4))\npar(oldPar)\ndev.off()\n\n\nestXYk5 = predXY(newSignals = onlineSummary[ , 6:11], \n                 newAngles = onlineSummary[ , 4], \n                 offlineSummary, numAngles = 3, k = 5)\n\ncalcError(estXYk5, actualXY)\n\npredXY = function(newSignals, newAngles, trainData, \n                  numAngles = 1, k = 3){\n  \n  closeXY = list(length = nrow(newSignals))\n  \n  for (i in 1:nrow(newSignals)) {\n    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)\n    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]),\n                           trainSS)\n  }\n\n  estXY = lapply(closeXY, function(x)\n                            sapply(x[ , 2:3], \n                                    function(x) mean(x[1:k])))\n  estXY = do.call(\"rbind\", estXY)\n  return(estXY)\n}\n\n```\n\n",
    "created" : 1518827801856.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3827970889",
    "id" : "5B423DD3",
    "lastKnownWriteTime" : 1518827668,
    "last_content_update" : 1518827820352,
    "path" : "C:/Users/dmurray/AnacondaProjects/MSDS7333/MSDS_7333_CaseStudyUnit6/MurrayD_NicholsC_LawJ_BattailardJ_QTW403_CaseStudy6.Rmd",
    "project_path" : "MurrayD_NicholsC_LawJ_BattailardJ_QTW403_CaseStudy6.Rmd",
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}