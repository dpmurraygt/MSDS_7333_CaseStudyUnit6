---
title: "Unit 6 Case Study 3"
output: html_notebook
---


```{r import, echo=FALSE}
library(tidyr)
library(dplyr)
library(fields)
library(lattice)

```

```{r data_cleanup, echo=FALSE}
#This is the code from Nolan and Lang Chapter 1
options(digits = 2)
setwd('~/DataScience/SMU_Data_Science/MSDS_QTW/MSDS_7333_CaseStudyUnit6/')

#Read in the text file to a matrix called txt
txt = readLines("Data/offline.final.trace.txt")

#get a count of lines that have a # in the first character location 
sum(substr(txt, 1, 1) == "#")

#total lines in the txt matrix
length(txt)

#strsplit the 4th line on semicolons, print to screen
strsplit(txt[4], ";")[[1]]

# store results of string of the 4th line to a vector
tokens = strsplit(txt[4], "[;=,]")[[1]]

# print tokens 1:10 to screen
tokens[1:10]

# extract the 2nd, 4th, 6:8 and 10th elements to the screen
tokens[c(2, 4, 6:8, 10)]

# get features for readings (all else not == handheld device)
tokens[ - ( 1:10 ) ]

#assign a matrix of everything except elements 1:10 to a 4 coloumn matrix called tmp
# build a matrix for each section of the data and bind them together using cbind
tmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE) # get all signals
mat = cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp), # repeat handheld device data
                   ncol = 6, byrow = TRUE), 
            tmp)
#print shape of mat to screen
dim(mat)

# make this extendable, create function to repeat process for each line in dataset
# this will create individual matrices for each line in the data (not efficient)
processLine =
function(x)
{
  tokens = strsplit(x, "[;=,]")[[1]]
  tmp = matrix(tokens[ - (1:10) ], ncol = 4, byrow = TRUE)
  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow = nrow(tmp),
               ncol = 6, byrow = TRUE), tmp)
}

# apply to 17 lines of first file at x,y = 0,0 and pos = 0.0
# creates 17 matrices, returns them in a list
tmp = lapply(txt[4:20], processLine)

# count the number of records in each matrix created
#use sapply (preserves dimensions tmp) to show the number of rows in each row in tmp
sapply(tmp, nrow)

# stack the matrices using rbind and do.call
offline = as.data.frame(do.call("rbind", tmp))
dim(offline)

# now do this for the entire dataset
#create a list called lines that contains the lines that don't start with a # 
lines = txt[ substr(txt, 1, 1) != "#" ]
tmp = lapply(lines, processLine)


# adjust induction function for issue where no readings for a position x,y and orientation
processLine = function(x)
{
  tokens = strsplit(x, "[;=,]")[[1]]
  
  if (length(tokens) == 10)  # this is the adjustment, checks to see if we have signal responses, if not, returns null
    return(NULL)
 
  tmp = matrix(tokens[ - (1:10) ], ncol= 4, byrow = TRUE)
  cbind(matrix(tokens[c(2, 4, 6:8, 10)], nrow(tmp), 6, 
               byrow = TRUE), tmp)
}

options(error = recover, warn = 1)
tmp = lapply(lines, processLine)
offline = as.data.frame(do.call("rbind", tmp), 
                        stringsAsFactors = FALSE)

# offline dataframe in tidy format with readings down instead of across
dim(offline)

# clean data and build represenation for analysis

# rename the columns, transform numeric values
names(offline) = c("time", "scanMac", "posX", "posY", "posZ", 
                   "orientation", "mac", "signal", 
                   "channel", "type")

numVars = c("time", "posX", "posY", "posZ", 
            "orientation", "signal")
offline[ numVars ] =  lapply(offline[ numVars ], as.numeric)

# drop all vars with 1 as mode and remove type variable
# only want to keep access point (type 3)
offline = offline[ offline$type == "3", ]
offline = offline[ , "type" != names(offline) ] # this filters out type from columns
dim(offline)

# transform time from ms to s in order to get POSIXt format
offline$rawTime = offline$time
offline$time = offline$time/1000 # convert from ms to s
class(offline$time) = c("POSIXt", "POSIXct")

unlist(lapply(offline, class))

# summary stats on our numeric vars
summary(offline[, numVars])

# only one MAC for our scanning device
summary(sapply(offline[ , c("mac", "channel", "scanMac")],
                as.factor))

# remove scanMac and posZ from offline df, no posZ in data and only one scanMac
offline = offline[ , !(names(offline) %in% c("scanMac", "posZ"))]

# exploring orientation, far more than 8 values for orientation
length(unique(offline$orientation))

# values distributed in clusters around what we'd expect
plot(ecdf(offline$orientation))

# build pdf export
pdf(file = "Geo_ECDFOrientation.pdf", width = 10, height = 7)
oldPar = par(mar = c(4, 4, 1, 1))
plot(ecdf(offline$orientation), pch = 19, cex = 0.3,
     xlim = c(-5, 365), axes = FALSE,
     xlab = "orientation", ylab = "Empirical CDF", main = "")
box()
axis(2)
axis(side = 1, at = seq(0, 360, by = 45))
par(oldPar)
dev.off()

pdf(file = "Geo_DensityOrientation.pdf", width = 10, height = 5)
oldPar = par(mar = c(4, 4, 1, 1))
plot(density(offline$orientation, bw = 2), 
 xlab = "orientation", main = "")
par(oldPar)
dev.off()

# instead, build function to round off orientation
roundOrientation = function(angles) {
  refs = seq(0, by = 45, length  = 9)
  q = sapply(angles, function(o) which.min(abs(o - refs))) # which angle is orientation value closest to? get index
  c(refs[1:8], 0)[q] # map index to reference positions, taking care to make sure 360 == 0
}

offline$angle = roundOrientation(offline$orientation)

# boxplot showing transforms of orientation to nearest 45 deg angle
with(offline, boxplot(orientation ~ angle,
                      xlab="nearest 45 degree angle",
                      ylab="orientation"))


pdf(file = "Geo_BoxplotAngle.pdf", width = 10)
oldPar = par(mar = c(4, 4, 1, 1))
par(oldPar)
dev.off()


# Exploring MAC Addresses
c(length(unique(offline$mac)), length(unique(offline$channel)))

# check counts of observationsf or MAC addresses
table(offline$mac)

# obviously extra MAC addresses, some with not many readings, get rid of those
# keep records from 7 top read devices (one more than we need)
subMacs = names(sort(table(offline$mac), decreasing = TRUE))[1:7]
# keep rows with subMacs identified only, discarding others
offline = offline[ offline$mac %in% subMacs, ]

# create a table of counts for mac and channel
macChannel = with(offline, table(mac, channel))
apply(macChannel, 1, function(x) sum(x > 0))
# one unique channel per MAC

# eliminate channel from offline dataset, not necessary for analysis
offline = offline[ , "channel" != names(offline)]



# EXPLORING POSITION OF HANDHELD DEVICE

# how many unique x,y positions?
locDF = with(offline, 
             by(offline, list(posX, posY), function(x) x))
length(locDF)
# way too many, > 166 quoted

# which locations are empty: 310
sum(sapply(locDF, is.null))

# remove nulls and we get 166 unique x,y locs, good to go
locDF = locDF[ !sapply(locDF, is.null) ]
length(locDF)

# get counts by x,y position, should be ~5300 110 readings * 8 angles * 6 positions 
locCounts = sapply(locDF, nrow)

locCounts = sapply(locDF, 
                   function(df) 
                     c(df[1, c("posX", "posY")], count = nrow(df)))

class(locCounts)

dim(locCounts)

locCounts[ , 1:8]

locCounts = t(locCounts)
plot(locCounts, type = "n", xlab = "", ylab = "")
text(locCounts, labels = locCounts[,3], cex = 0.8, srt = 45)

pdf(file = "Geo_XYByCount.pdf", width = 10)
oldPar = par(mar = c(3.1, 3.1, 1, 1))

locCounts = t(locCounts)
plot(locCounts, type = "n", xlab = "", ylab = "")
text(locCounts, labels = locCounts[,3], cex = .8, srt = 45)

par(oldPar)
dev.off()


# CREATING A FUNCTION TO PREPARE THE DATA
readData = 
  function(filename = 'Data/offline.final.trace.txt', 
           subMacs = c("00:0f:a3:39:e1:c0", "00:0f:a3:39:dd:cd", "00:14:bf:b1:97:8a",
                       "00:14:bf:3b:c7:c6", "00:14:bf:b1:97:90", "00:14:bf:b1:97:8d",
                       "00:14:bf:b1:97:81"))
  {
    txt = readLines(filename)
    lines = txt[ substr(txt, 1, 1) != "#" ]
    tmp = lapply(lines, processLine)
    offline = as.data.frame(do.call("rbind", tmp), 
                            stringsAsFactors= FALSE) 
    
    names(offline) = c("time", "scanMac", 
                       "posX", "posY", "posZ", "orientation", 
                       "mac", "signal", "channel", "type")
    
     # keep only signals from access points
    offline = offline[ offline$type == "3", ]
    
    # drop scanMac, posZ, channel, and type - no info in them
    dropVars = c("scanMac", "posZ", "channel", "type")
    offline = offline[ , !( names(offline) %in% dropVars ) ]
    
    # drop more unwanted access points
    offline = offline[ offline$mac %in% subMacs, ]
    
    # convert numeric values
    numVars = c("time", "posX", "posY", "orientation", "signal")
    offline[ numVars ] = lapply(offline[ numVars ], as.numeric)

    # convert time to POSIX
    offline$rawTime = offline$time
    offline$time = offline$time/1000
    class(offline$time) = c("POSIXt", "POSIXct")
    
    # round orientations to nearest 45
    offline$angle = roundOrientation(offline$orientation)
      
    return(offline)
  }

offlineRedo = readData()

# check for equality
identical(offline, offlineRedo)

# what variables did we use as global? these our are dependencies
library(codetools)
findGlobals(readData, merge =FALSE)$variables
```

```{r eda, echo=FALSE}
# INVESTIGATING SIGNAL STRENGTH

pdf(file = "Geo_BoxplotSignalByMacAngle.pdf", width = 7)
oldPar = par(mar = c(3.1, 3, 1, 1))

library(lattice)
# investigate variability of angle for each MAC given one x,y position
# we exclude MAC 00:0f:a3:39:dd:cd here, can see that angle affects
# the signal fr some mac addresses, especially those with stronger signals
bwplot(signal ~ factor(angle) | mac, 
       data = offline, 
       subset = posX == 2 & posY == 12 
                & mac != "00:0f:a3:39:dd:cd", 
       layout = c(2,3))

par(oldPar)
dev.off()

# overall statistics for signal, range of -98 to -25 (lower is stronger)
summary(offline$signal)

pdf(file = "Geo_DensitySignalByMacAngle.pdf", width = 8, height = 12)
oldPar = par(mar = c(3.1, 3, 1, 1))

# investigate distribution of signals for one x,y with distribution for each angle
# non-normality and dual-modal apparent, e.g. 00:14:bf:b1:97:8a, at 270 deg orientation
densityplot( ~ signal | mac + factor(angle), 
             data = offline,
             subset = posX == 24 & posY == 4 & 
                         mac != "00:0f:a3:39:dd:cd",
             bw = 0.5, plot.points = FALSE)

par(oldPar)
dev.off()

#offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ]

# create table of summary stats by Location, Angle and AP
offline$posXY = paste(offline$posX, offline$posY, sep = "-") # concat x,y

byLocAngleAP = with(offline, 
                    by(offline, list(posXY, angle, mac), 
                       function(x) x))

# calculate summary statistics, reduce down to single summary line
signalSummary = 
  lapply(byLocAngleAP,            
         function(oneLoc) {
           ans = oneLoc[1, ]
           ans$medSignal = median(oneLoc$signal)
           ans$avgSignal = mean(oneLoc$signal)
           ans$num = length(oneLoc$signal)
           ans$sdSignal = sd(oneLoc$signal)
           ans$iqrSignal = IQR(oneLoc$signal)
           ans
           })

# bind all the summary lines together
offlineSummary = do.call("rbind", signalSummary)     

pdf(file = "Geo_BoxplotSignalSDByAvg.pdf", width = 10)
oldPar = par(mar = c(3.1, 3, 1, 1))

# create box and whisker for standard deviation for each avg Signal calculated in summary
# shows us how variable signal ranges can be
# more variable the stronger the signal is
breaks = seq(-90, -30, by = 5)
bwplot(sdSignal ~ cut(avgSignal, breaks = breaks),
       data = offlineSummary, 
       subset = mac != "00:0f:a3:39:dd:cd",
       xlab = "Mean Signal", ylab = "SD Signal")

par(oldPar)
dev.off()

pdf(file = "Geo_ScatterMean-Median.pdf", width = 10)
oldPar = par(mar = c(4.1, 4.1, 1, 1))

# examine skewness of signal strength (avg - med signal) vs num observations
# if normal should be higher densities in center
with(offlineSummary,
     smoothScatter((avgSignal - medSignal) ~ num,
                   xlab = "Number of Observations", 
                   ylab = "mean - median"))
abline(h = 0, col = "#984ea3", lwd = 2)

# fit LOESS line, shows that there is not a lot of difference or trend
# skewness is minimal
lo.obj = 
  with(offlineSummary,
       loess(diff ~ num, 
             data = data.frame(diff = (avgSignal - medSignal),
                               num = num)))

lo.obj.pr = predict(lo.obj, newdata = data.frame(num = (70:120)))
lines(x = 70:120, y = lo.obj.pr, col = "#4daf4a", lwd = 2)

par(oldPar)
dev.off()
 

# THE RELATIONSHIP BETWEEN SIGNAL AND DISTANCE

# contour plot investigation
# one MAC and one orientaiton
oneAPAngle = subset(offlineSummary, 
                    mac == subMacs[5] & angle == 0)


library(fields)
# tps = thin plate splines, fit surface to signal strength values at observed locations
# must pass a Z here, which is our avg signal, this will reflect our color
smoothSS = Tps(oneAPAngle[, c("posX","posY")], 
               oneAPAngle$avgSignal)

vizSmooth = predictSurface(smoothSS)

plot.surface(vizSmooth, type = "C")

# add locations where measurements were taken
points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5)

# create a function for charting purposes, to include multiple contour plots
surfaceSS = function(data, mac, angle = 45) {
  require(fields)
  oneAPAngle = data[ data$mac == mac & data$angle == angle, ]
  smoothSS = Tps(oneAPAngle[, c("posX","posY")], 
                 oneAPAngle$avgSignal)
  vizSmooth = predictSurface(smoothSS)
  plot.surface(vizSmooth, type = "C", 
               xlab = mac, ylab = "", xaxt = "n", yaxt = "n")
  points(oneAPAngle$posX, oneAPAngle$posY, pch=19, cex = 0.5) 
}

parCur = par(mfrow = c(2,2), mar = rep(1, 4))

# make 4 calls, shows corridor effect, signal strength of course strongest closest to AP
mapply(surfaceSS, mac = subMacs[ rep(c(5, 1,2), each = 2) ], 
       angle = rep(c(0, 135, 180), 2),
       data = list(data = offlineSummary))
 
par(parCur)

# the two similar macs are subMacs[1,2]
# remove similar MAC
offlineSummary = subset(offlineSummary, mac != subMacs[2])

# create a mtrix with relevant positions for six access points on floor plan
AP = matrix( c( 7.5, 6.3, 2.5, -.8, 12.8, -2.8,  
                1, 14, 33.5, 9.3,  33.5, 2.8),
            ncol = 2, byrow = TRUE,
            dimnames = list(subMacs[ -2 ], c("x", "y") ))

AP

# relationship between signal stregnth and distance from AP
# distances from locations of the device emitting vs access point receiving
diffs = offlineSummary[ , c("posX", "posY")] - 
          AP[ offlineSummary$mac, ] # ordered and indexed by offlineSummary

offlineSummary$dist = sqrt(diffs[ , 1]^2 + diffs[ , 2]^2)

xyplot(signal ~ dist | factor(mac) + factor(angle), 
       data = offlineSummary, pch = 19, cex = 0.3,
       xlab ="distance")

pdf(file="Geo_ScatterSignalDist.pdf", width = 7, height = 10)
oldPar = par(mar = c(3.1, 3.1, 1, 1))
library(lattice)
xyplot(signal ~ dist | factor(mac) + factor(angle), 
       data = offlineSummary, pch = 19, cex = 0.3,
       xlab ="distance")
par(oldPar)
dev.off()

```

```{r knn_work, echo=FALSE}

# using only signals to APs from previously trained locations
# need to reformat data so signal strength is across columns

macs = unique(offlineSummary$mac)
# read test data
online = readData("Data/online.final.trace.txt", subMacs = macs)

# set up unique XY
online$posXY = paste(online$posX, online$posY, sep = "-")

# 60 unique positions
length(unique(online$posXY))

# using only one orientation for each location
tabonlineXYA = table(online$posXY, online$angle)
tabonlineXYA[1:10, ]

# pivot data to include signals across columns
# take the mean of signal for each mac position along columns
keepVars = c("posXY", "posX", "posY", "orientation", "angle")
byLoc = with(online, 
             by(online, list(posXY), 
                function(x) {
                  ans = x[1, keepVars]
                  avgSS = tapply(x$signal, x$mac, mean)
                  y = matrix(avgSS, nrow = 1, ncol = 6,
                        dimnames = list(ans$posXY, names(avgSS)))
                  cbind(ans, y)
                }))

onlineSummary = do.call("rbind", byLoc)  

dim(onlineSummary)

# rename
names(onlineSummary)

# want to find records in offline data (training) that have similar orientations to our new observations
# orientation CAN impact signal strength as already evidenced visually

m = 3; angleNewObs = 230
refs = seq(0, by = 45, length  = 8)
nearestAngle = roundOrientation(angleNewObs)
  
if (m %% 2 == 1) {
  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
} else {
  m = m + 1
  angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
  if (sign(angleNewObs - nearestAngle) > -1) 
    angles = angles[ -1 ]
  else 
    angles = angles[ -m ]
}
angles = angles + nearestAngle
angles[angles < 0] = angles[ angles < 0 ] + 360
angles[angles > 360] = angles[ angles > 360 ] - 360

# with desired angles, select observations from offlineSummary for training
offlineSubset = 
  offlineSummary[ offlineSummary$angle %in% angles, ]

# then reshape training set to match test set, with signals across columns
reshapeSS = function(data, varSignal = "signal", 
                     keepVars = c("posXY", "posX","posY")) {
  byLocation =
    with(data, by(data, list(posXY), 
                  function(x) {
                    ans = x[1, keepVars]
                    avgSS = tapply(x[ , varSignal ], x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = 6,
                               dimnames = list(ans$posXY,
                                               names(avgSS)))
                    cbind(ans, y)
                  }))

  newDataSS = do.call("rbind", byLocation)
  return(newDataSS)
}

trainSS = reshapeSS(offlineSubset, varSignal = "avgSignal")

# wrap code to select angles and reshape the training set
# takes angle of new observation and associated angles from dataset via m given an offline set signals
selectTrain = function(angleNewObs, signals = NULL, m = 1){
  # m is the number of angles to keep between 1 and 5
  refs = seq(0, by = 45, length  = 8)
  nearestAngle = roundOrientation(angleNewObs)
  
  if (m %% 2 == 1) 
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
  else {
    m = m + 1
    angles = seq(-45 * (m - 1) /2, 45 * (m - 1) /2, length = m)
    if (sign(angleNewObs - nearestAngle) > -1) 
      angles = angles[ -1 ]
    else 
      angles = angles[ -m ]
  }
  angles = angles + nearestAngle
  angles[angles < 0] = angles[ angles < 0 ] + 360
  angles[angles > 360] = angles[ angles > 360 ] - 360
  angles = sort(angles) 
  
  offlineSubset = signals[ signals$angle %in% angles, ]
  reshapeSS(offlineSubset, varSignal = "avgSignal")
}

# use angle of 130 for offline summary taking 130 and two closest angles for training set
# reshape
train130 = selectTrain(130, offlineSummary, m = 3)

head(train130)

length(train130[[1]])




# FINDING NEAREST NEIGHBORS
# takes numeric vector of 6 signal strengths and result of selectTrain()
findNN = function(newSignal, trainSubset) {
  diffs = apply(trainSubset[ , 4:9], 1, 
                function(x) x - newSignal) # this inverts, places x,y on cols when called as.numeric
  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) ) # this gets our distance (euclidean)
  closest = order(dists) #(orders them ascending)
  return(trainSubset[closest, 1:3 ]) # returns the subset from training with closest distances, gives x,y
}


# weighted nearest neighbors, returns numerator of weight 1/distance
findWtdNN = function(newSignal, trainSubset) {
  diffs = apply(trainSubset[ , 4:9], 1, 
                function(x) x - newSignal) # this inverts, places x,y on cols when called as.numeric
  dists = apply(diffs, 2, function(x) sqrt(sum(x^2)) ) # this gets our distance (euclidean)
  closest = order(dists) # orders distances ascending
  closeXY = trainSubset[closest, 1:3 ]
  weight = as.numeric(1/dists[closest])
  return(cbind(closeXY, weight) )
}

# prediction using nearest neighbors from training set
predXY = function(newSignals, newAngles, trainData, 
                  numAngles = 1, k = 3){
  
  closeXY = list(length = nrow(newSignals))
  
  for (i in 1:nrow(newSignals)) {
    trainSS = selectTrain(newAngles[i], trainData, m = numAngles) # select training set based on angle of test obs, num of close angles
    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]), trainSS)
  }
  estXY = lapply(closeXY, 
                 function(x) sapply(x[ , 2:3], 
                                    function(x) mean(x[1:k])))
  estXY = do.call("rbind", estXY)
  return(estXY)
}


predXYwtd = function(newSignals, newAngles, trainData, 
                     numAngles = 1, k = 3){
  
  closeXY = list(length = nrow(newSignals))
  
  for (i in 1:nrow(newSignals)) {
    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)
    base = findWtdNN(newSignal = as.numeric(newSignals[i, ]), trainSS) # get matrix of x,y,weights
    wts = append(base[1:k, 4]/sum(base[1:k, 4]), rep(0, nrow(base)-k))  # calculate weights, append zero array for delta of len-k
    base[, 2:3] = base[, 2:3]*wts # multiply weights array * matrix of x,y to get weighted vals ready to sum in lapply() below
    closeXY[[i]] = base[,1:3] # append adjusted x,y values
  }
  estXY = lapply(closeXY, 
                 function(x) sapply(x[ , 2:3], function(x) sum(x))) # sum all as neighbors > k == 0 now
  estXY = do.call("rbind", estXY)
  return(estXY)
}

estXYk3 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 3)

estXYk1 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 1)

estXYk3wtd = predXYwtd(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 3)

estXYk5 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 5)

estXYk5wtd = predXYwtd(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 5)
```


```{r error_checking, echo=FALSE}
floorErrorMap = function(estXY, actualXY, trainPoints = NULL, AP = NULL){
  
    plot(0, 0, xlim = c(0, 35), ylim = c(-3, 15), type = "n",
         xlab = "", ylab = "", axes = FALSE)
    box()
    if ( !is.null(AP) ) points(AP, pch = 15)
    if ( !is.null(trainPoints) )
      points(trainPoints, pch = 19, col="grey", cex = 0.6)
    
    points(x = actualXY[, 1], y = actualXY[, 2], 
           pch = 19, cex = 0.8 )
    points(x = estXY[, 1], y = estXY[, 2], 
           pch = 8, cex = 0.8 )
    segments(x0 = estXY[, 1], y0 = estXY[, 2],
             x1 = actualXY[, 1], y1 = actualXY[ , 2],
             lwd = 2, col = "red")
}

trainPoints = offlineSummary[ offlineSummary$angle == 0 & 
                              offlineSummary$mac == "00:0f:a3:39:e1:c0" ,
                        c("posX", "posY")]

pdf(file="GEO_FloorPlanK3Errors.pdf", width = 10, height = 7)
oldPar = par(mar = c(1, 1, 1, 1))

floorErrorMap(estXYk3, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
par(oldPar)
dev.off()

pdf(file="GEO_FloorPlanK1Errors.pdf", width = 10, height = 7)
oldPar = par(mar = c(1, 1, 1, 1))
floorErrorMap(estXYk1, onlineSummary[ , c("posX","posY")], 
              trainPoints = trainPoints, AP = AP)
par(oldPar)
dev.off()

calcError = 
function(estXY, actualXY) 
   sum( rowSums( (estXY - actualXY)^2) )

actualXY = onlineSummary[ , c("posX", "posY")]
sapply(list(estXYk1, estXYk3, estXYk3wtd, estXYk5, estXYk5wtd), calcError, actualXY)

v = 11
permuteLocs = sample(unique(offlineSummary$posXY))
permuteLocs = matrix(permuteLocs, ncol = v, 
                     nrow = floor(length(permuteLocs)/v))

onlineFold = subset(offlineSummary, posXY %in% permuteLocs[ , 1])

reshapeSS = function(data, varSignal = "signal", 
                     keepVars = c("posXY", "posX","posY"),
                     sampleAngle = FALSE, 
                     refs = seq(0, 315, by = 45)) {
  byLocation =
    with(data, by(data, list(posXY), 
                  function(x) {
                    if (sampleAngle) {
                      x = x[x$angle == sample(refs, size = 1), ]}
                    ans = x[1, keepVars]
                    avgSS = tapply(x[ , varSignal ], x$mac, mean)
                    y = matrix(avgSS, nrow = 1, ncol = 6,
                               dimnames = list(ans$posXY,
                                               names(avgSS)))
                    cbind(ans, y)
                  }))

  newDataSS = do.call("rbind", byLocation)
  return(newDataSS)
}

offline = offline[ offline$mac != "00:0f:a3:39:dd:cd", ]

keepVars = c("posXY", "posX","posY", "orientation", "angle")

onlineCVSummary = reshapeSS(offline, keepVars = keepVars, 
                            sampleAngle = TRUE)

onlineFold = subset(onlineCVSummary, 
                    posXY %in% permuteLocs[ , 1])

offlineFold = subset(offlineSummary,
                     posXY %in% permuteLocs[ , -1])

estFold = predXYwtd(newSignals = onlineFold[ , 6:11], 
                 newAngles = onlineFold[ , 4], 
                 offlineFold, numAngles = 3, k = 3)

actualFold = onlineFold[ , c("posX", "posY")]
calcError(estFold, actualFold)

# NOW WITH WEIGHTED COMPARISON
K = 20
err = rep(0, K)
err_wtd = rep(0,K) # weighted error

for (j in 1:v) {
  onlineFold = subset(onlineCVSummary, 
                      posXY %in% permuteLocs[ , j])
  offlineFold = subset(offlineSummary,
                       posXY %in% permuteLocs[ , -j])
  actualFold = onlineFold[ , c("posX", "posY")]
  
  for (k in 1:K) {
    estFold = predXY(newSignals = onlineFold[ , 6:11],
                     newAngles = onlineFold[ , 4], 
                     offlineFold, numAngles = 3, k = k)
    err[k] = err[k] + calcError(estFold, actualFold)
    
    estFold_wtd = predXYwtd(newSignals = onlineFold[ , 6:11], # add in weighted calculations
                     newAngles = onlineFold[ , 4], 
                     offlineFold, numAngles = 3, k = k)
    err_wtd[k] = err_wtd[k] + calcError(estFold_wtd, actualFold)
  }
}

pdf(file = "Geo_CVChoiceOfK.pdf", width = 10, height = 6)
oldPar = par(mar = c(4, 3, 1, 1))
plot(y = err, x = (1:K),  type = "l", lwd= 2,
     ylim = c(0, 2100),
     xlab = "Number of Neighbors",
     ylab = "Sum of Square Errors")
lines(y=err_wtd, x=1:K, lty = 2, lwd=2, col='red')


rmseMin = min(err)
kMin = which(err == rmseMin)[1]

rmseMin_wtd = min(err_wtd)
kMin_wtd = which(err_wtd == rmseMin_wtd)[1]

# additional code not in book:

segments(x0 = 0, x1 = kMin, y0 = rmseMin, col = gray(0.4), 
         lty = 2, lwd = 2)
segments(x0 = kMin, x1 = kMin, y0 = 1100,  y1 = rmseMin, 
         col = grey(0.4), lty = 2, lwd = 2)

#mtext(kMin, side = 1, line = 1, at = kMin, col = grey(0.4))
text(x = kMin - 2, y = rmseMin + 40, 
     label = as.character(round(rmseMin)), col = grey(0.4))
par(oldPar)
dev.off()


estXYk5 = predXY(newSignals = onlineSummary[ , 6:11], 
                 newAngles = onlineSummary[ , 4], 
                 offlineSummary, numAngles = 3, k = 5)

calcError(estXYk5, actualXY)

predXY = function(newSignals, newAngles, trainData, 
                  numAngles = 1, k = 3){
  
  closeXY = list(length = nrow(newSignals))
  
  for (i in 1:nrow(newSignals)) {
    trainSS = selectTrain(newAngles[i], trainData, m = numAngles)
    closeXY[[i]] = findNN(newSignal = as.numeric(newSignals[i, ]),
                           trainSS)
  }

  estXY = lapply(closeXY, function(x)
                            sapply(x[ , 2:3], 
                                    function(x) mean(x[1:k])))
  estXY = do.call("rbind", estXY)
  return(estXY)
}

```


